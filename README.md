
# ğŸŒŠ Reservoir PINN Simulator ğŸš€

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

ğŸ’§ This **3D Reservoir PINN Simulator** Streamlit application leverages Physics-Informed Neural Networks (PINNs) to model pressure dynamics within a 3D reservoir. It tackles a complex 3D partial differential equation (PDE) for single-phase fluid flow, seamlessly integrating sparse data, boundary conditions, and initial conditions as part of the loss function of the neural network architecture.

What you can do with the simulator:
* âš™ï¸ Input your own reservoir parameters.
* ğŸ§  Train new PINN models or load existing ones.
* ğŸ“Š Visualize pressure fields with static slices and dynamic animations.
* ğŸ—£ï¸ Query pressure values using cutting-edge LLMs (Deepseek and OpenAI)
* ğŸ“ˆ Track experiments and manage models with MLflow integration.
* ğŸ“– Explore a detailed Jupyter Notebook explaining the PINN implementation.

---
### Demo Video Link

![reservoir_demo](assets/reservoir_demo.gif)
----
## âœ¨ Features

* **ğŸ“ Input Parameters:** Configure reservoir settings like porosity, permeability, viscosity, compressibility, injection rate, well position, base pressure, and pressure scale.
* **ğŸ’¾ Data Upload:** Easily upload CSV files (x, y, z, t, p columns) or use the provided `data/reservoir_data.csv`. Visualize your data with a 3D scatter plot in the sidebar!
* **ğŸ‹ï¸ Model Training:** Train new PINN models with real-time loss updates displayed in the sidebar integrated with MLflow.
* **ğŸ“‚ Model Loading:** Load previously trained models directly from MLflow runs for quick visualizations and querying.
* **ğŸ–¼ï¸ Visualization:** Generate static 2D slices of the pressure field at user-defined times and z-levels.
* **ğŸ¬ Animation:** Create captivating animated GIFs showcasing the evolution of the pressure field over time.
* **ğŸ¤– LLM Queries:** Interact with your simulation by querying pressure at specific 3D coordinates (x, y, z, t) using DeepSeek or OpenAI LLMs.
* **ğŸ“Š MLflow Tracking:** Keep track of all your experiments! Parameters, metrics (losses), and artifacts (models, loss plots) are logged for comprehensive experiment management.
* **ğŸ³ Docker Support:** Run the entire application in a GPU-compatible Docker container for easy deployment and reproducibility.

---

## ğŸ“ File Structure

```text
reservoir_pinn_simulator/
â”œâ”€â”€ .env.example                   # ğŸ”‘ Template for environment variables
â”œâ”€â”€ .gitignore                    # ğŸ™ˆ Git ignore file
â”œâ”€â”€ README.md                     # ğŸ“– This awesome project documentation
â”œâ”€â”€ requirements.txt              # ğŸ“œ Python dependencies, including mlflow
â”œâ”€â”€ Dockerfile                    # ğŸ³ Docker configuration for GPU support
â”œâ”€â”€ data/
â”‚   â””â”€â”€ reservoir_data.csv        # ğŸ“‰ Default dataset with 50 pressure points
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ reservoir_pinn_notebook.ipynb  # ğŸ““ Jupyter Notebook explaining PINN
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py               # ğŸ“¦ Makes src a Python package
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ server.py             # ğŸŒ FastAPI server for LLM queries
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ pinn.py               # ğŸ§  PINN model definition
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ plotting.py           # ğŸ“ˆ Plotting functions for 3D visualization
â”‚   â”‚   â””â”€â”€ training.py           # ğŸ’ª PINN training logic
â”‚   â””â”€â”€ app.py                    # ğŸˆ Streamlit app with training and loading
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ reservoir_demo.gif        # ğŸ—ï¸ Demo video of simulator
â””â”€â”€ mlruns/                       #  mlflow Auto-generated by MLflow for experiment tracking
```


## ğŸ› ï¸ Prerequisites

* **ğŸ Python 3.12+:** Required for local setup.
* **ğŸ³ Docker:** For containerized deployment (with NVIDIA Container Toolkit for GPU support).
* **ğŸ’» GPU (Optional):** NVIDIA GPU with CUDA 11.8 for accelerated training.
* **ğŸ§  Ollama:** For local DeepSeek R1 1.5B LLM.
* **ğŸ–¼ï¸ Pillow:** For GIF animation rendering (included in `requirements.txt`).
* **ğŸ“Š MLflow:** For experiment tracking and model persistence.
* **ğŸAnaconda:** For managing python environment.

---

## âš™ï¸ Local Setup

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/Danny024/reservoir_pinn_simulator.git
    cd reservoir_pinn_simulator
    ```

2.  **Set up PYTHONPATH (Important!):**
    ```bash
    export PYTHONPATH=$PYTHONPATH:/path/to/your/reservoir_pinn_simulator
    ```
    
3.  **Create a Conda Environment:**
    ```bash
    conda create -n reservoir_simulator python=3.12
    conda activate reservoir_simulator
    ```

4.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

5.  **Configure Environment:**
    * Copy `.env.example` to `.env`:
        ```bash
        cp .env.example .env
        ```
    * Edit `.env` to add your OpenAI API key (optional):
        ```env
        OPENAI_API_KEY=your_openai_api_key_here
        ```
        Leave blank if you plan to use DeepSeek:
        ```env
        OPENAI_API_KEY=
        ```

6.  **Install and Configure Ollama:**
    * Install Ollama: [https://ollama.ai](https://ollama.ai)
    * Pull DeepSeek model:
        ```bash
        ollama pull deepseek-r1:1.5b
        ```
    * Start Ollama server (usually runs in the background after installation, but you can manually start if needed):
        ```bash
        ollama serve
        ```

7.  **Prepare Assets:**
    * Ensure `assets/pinn_architecture.png` exists. You can generate it using `notebooks/reservoir_pinn_notebook.ipynb` or provide a placeholder image.

8.  **Run MLflow Server:**
    ```bash
    #mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri file://$(pwd)/mlruns --default-artifact-root file://$(pwd)/artifacts
    mlfow ui
    ```

9.  **Run FastAPI Server (for LLM queries):**
    ```bash
    uvicorn src.api.server:app --host 0.0.0.0 --port 8000
    ```

10. **Run Streamlit App:**
    ```bash
    streamlit run src/app.py
    ```

---

## ğŸ³ Docker Setup

1.  **Install Docker and NVIDIA Container Toolkit:**
    * **Docker (Ubuntu):**
        ```bash
        sudo apt-get update
        sudo apt-get install -y docker.io
        sudo systemctl start docker
        sudo systemctl enable docker
        ```
    * **NVIDIA Container Toolkit (for GPU support):**
        ```bash
        curl -fsSL [https://nvidia.github.io/libnvidia-container/gpgkey](https://nvidia.github.io/libnvidia-container/gpgkey) | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
        && curl -s -L [https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list](https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list) | \
        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
        sudo apt-get update
        sudo apt-get install -y nvidia-container-toolkit
        sudo nvidia-ctk runtime configure --runtime=docker
        sudo systemctl restart docker
        ```

2.  **Build Docker Image:**
    ```bash
    docker build -t reservoir-pinn-simulator .
    ```

3.  **Run Docker Container:**
    * **With GPU:**
        ```bash
        docker run --gpus all -p 8501:8501 -p 8000:8000 -p 5000:5000 -p 11434:11434 reservoir-pinn-simulator
        ```
    * **CPU-only:**
        ```bash
        docker run -p 8501:8501 -p 8000:8000 -p 5000:5000 -p 11434:11434 reservoir-pinn-simulator
        ```
    *(The internal Ollama server within Docker typically runs on port 11434)*

4.  **Persist MLflow Data (Optional):**
    You can manually create directories on your host machine if they don't exist:
    ```bash
    mkdir -p mlruns artifacts
    ```
    Then run the container with volume mounts:
    ```bash
    docker run --gpus all -p 8501:8501 -p 8000:8000 -p 5000:5000 -p 11434:11434 \
    -v $(pwd)/mlruns:/app/mlruns \
    -v $(pwd)/artifacts:/app/artifacts \
    reservoir-pinn-simulator
    ```

---

## ğŸš€ Usage

1.  **Access the Application:**
    * **Streamlit GUI:** [http://localhost:8501](http://localhost:8501)
    * **MLflow UI:** [http://localhost:5000](http://localhost:5000)
    * *(Ollama usually runs on `http://localhost:11434` if run locally, or is accessed internally within Docker)*

2.  **âš™ï¸ Configure Parameters:**
    * In the "Reservoir Parameters" section of the Streamlit app, set values for $\phi$ (porosity), $k$ (permeability), $\mu$ (viscosity), $c_t$ (total compressibility), $q_0$ (injection rate), well position, $p_{base}$, and $p_{scale}$.

3.  **ğŸ’¾ Upload Data:**
    * Upload a CSV file containing columns: `x, y, z, t, p`.
    * Alternatively, use the default `data/reservoir_data.csv`.
    * A 3D scatter plot of the uploaded data points will appear in the sidebar.

4.  **ğŸ§  Train or Load Model:**
    * **Train New Model:** Navigate to "Training Parameters", specify the number of epochs, and click "Train Model". Monitor training losses and the MLflow run ID in the sidebar.
    * **Load Trained Model:** Select an existing MLflow run ID from the dropdown and click "Load Trained Model" to use a pre-trained model.

5.  **ğŸ“Š Visualize Pressure:**
    * Go to the "Visualize 3D Pressure Field Slice" section.
    * Select the desired time ($t$) and z-slice level.
    * Click "Visualize Pressure Field" to see the 2D slice.

6.  **ğŸ¬ Generate Animation:**
    * In the "Generate 3D Pressure Field Animation" section, choose a z-slice.
    * Click "Generate Pressure Animation" to create and view an animated GIF of the pressure field evolving over time.

7.  **ğŸ—£ï¸ Query Pressure with LLM:**
    * Head to the "Query Pressure with LLM" section.
    * Select either "DeepSeek" or "OpenAI" as your LLM provider.
    * Enter your query in natural language (e.g., "What is the pressure at x=0.5, y=0.5, z=0.5, t=0.5?").
    * Click "Submit Query" to get the pressure prediction.
---

## ğŸ”— MLflow Integration

* **ğŸ” Access Runs:** Open your MLflow UI (default: [http://localhost:5000](http://localhost:5000)) to view the `3D_Reservoir_PINN` experiment. Here you can find:
    * **Parameters:** $p_{base}$, $p_{scale}$, learning rate, epochs, etc.
    * **Metrics:** Training losses (e.g., total loss, PDE loss, data loss).
    * **Artifacts:** Saved model files, loss plots.
* **ğŸ”„ Load Models Programmatically:** Use the run ID (visible in the Streamlit sidebar or MLflow UI) to load models in your Python scripts or notebooks:
    ```python
    import mlflow.pytorch

    run_id = "<your_run_id>" # Replace with actual run ID
    model_uri = f"runs:/{run_id}/model"
    model = mlflow.pytorch.load_model(model_uri)
    ```
* **âš–ï¸ Compare Runs:** Utilize the MLflow UI to compare different training runs based on their loss metrics and configured parameters. This is invaluable for hyperparameter tuning and model selection!

---

## ğŸ¤” Troubleshooting

* **`ModuleNotFoundError`:**
    * Ensure all dependencies from `requirements.txt` are installed in your active environment: `pip install -r requirements.txt`.
    * Verify `PYTHONPATH` is set correctly if running locally.

* **MLflow Issues:**
    * Confirm the MLflow server is running and accessible (default: `http://localhost:5000`).
    * Check the `mlruns/` directory for experiment data. Ensure it's correctly mounted if using Docker with persistent storage.

* **Docker Build Fails:**
    * Make sure all necessary files exist (e.g., `data/reservoir_data.csv`, `assets/pinn_architecture.png`).
    * Verify you have internet access for downloading packages and base images during the build.

* **Docker Container Fails to Start/Run:**
    * Check container logs for errors: `docker logs <container_id_or_name>`.
    * **Port Conflicts:** If ports 8501, 8000, 5000, or 11434 are already in use on your host, map to different host ports. For example:
        ```bash
        docker run --gpus all -p 8502:8501 -p 8001:8000 -p 5001:5000 -p 11435:11434 reservoir-pinn-simulator
        ```
        Then access Streamlit at `http://localhost:8502`, FastAPI at `http://localhost:8001`, etc.

* **GPU Issues (Docker):**
    * Ensure NVIDIA drivers are correctly installed on your host machine.
    * Verify the NVIDIA Container Toolkit is properly installed and configured. Test with:
        ```bash
        docker run --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
        ```
        This command should output GPU information if everything is set up correctly.

* **Ollama Fails / LLM Issues:**
    * **Local:** Ensure the Ollama server is running (`ollama serve`). Confirm you've pulled the model (`ollama pull deepseek-coder:1.3b` or similar).
    * **Docker:** Check container logs for messages related to Ollama starting or model pulling. The Dockerfile attempts to pull the model during the build.
    * If using OpenAI, ensure your `OPENAI_API_KEY` in the `.env` file is correct and has credit.

* **GIF Animation Issues:**
    * Make sure the `pillow` library is installed: `pip show pillow`. It should be included in `requirements.txt`.

---

## ğŸ“Œ TO DO
1. Make use of real reservoir dataset
2. Design PDE for multiphase flow
3. Write Code base in C++ and C# for high performance and efficiency

---

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE)

