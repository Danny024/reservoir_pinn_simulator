{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Reservoir PINN Simulator: Detailed Explanation\n",
    "\n",
    "This Jupyter Notebook explains the Python code for a Physics-Informed Neural Network (PINN) that simulates pressure in a 3D reservoir. The code solves a 3D partial differential equation (PDE) for single-phase fluid flow, incorporating data from a CSV file, boundary conditions, and initial conditions. It includes static 2D slice visualizations and an animation of the pressure field.\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.8+\n",
    "- Required libraries: `torch`, `numpy`, `pandas`, `matplotlib`, `ffmpeg-python`\n",
    "- FFmpeg installed for animation rendering\n",
    "- A sample `data/reservoir_data.csv` file with columns `x`, `y`, `z`, `t`, `p` (provided with 50 points)\n",
    "\n",
    "## Overview\n",
    "The code:\n",
    "1. Defines reservoir parameters and a PINN model for 3D input (x, y, z, t).\n",
    "2. Computes the PDE residual for the 3D flow equation.\n",
    "3. Loads sparse data from `data/reservoir_data.csv`.\n",
    "4. Generates collocation, boundary, and initial condition points in 3D.\n",
    "5. Trains the PINN using Adam and L-BFGS optimizers.\n",
    "6. Validates the model and visualizes results (2D slices and animation).\n",
    "7. Plots the PINN architecture.\n",
    "\n",
    "The PDE is:\n",
    "\\[ \\phi c_t \\frac{\\partial p}{\\partial t} - \\frac{k}{\\mu} \\left( \\frac{\\partial^2 p}{\\partial x^2} + \\frac{\\partial^2 p}{\\partial y^2} + \\frac{\\partial^2 p}{\\partial z^2} \\right) = q \\]\n",
    "where \\( q = q_0 \\exp\\left( -\\frac{(x - x_w)^2 + (y - y_w)^2 + (z - z_w)^2}{2 \\sigma^2} \\right) \\) is the source term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "This cell imports the necessary libraries for numerical computations, neural networks, data handling, visualization, and animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "# Explanation:\n",
    "# - torch: PyTorch library for neural networks and tensor operations.\n",
    "# - torch.nn: Neural network modules (e.g., layers, activations).\n",
    "# - numpy: Numerical computations for arrays and meshes.\n",
    "# - matplotlib.pyplot: Plotting for static visualizations.\n",
    "# - pandas: Data handling for CSV files.\n",
    "# - torch.optim.lr_scheduler: Learning rate scheduling for optimization.\n",
    "# - matplotlib.animation: For creating animations of the pressure field.\n",
    "# - IPython.display.HTML: Displays animations in the notebook.\n",
    "# - base64: Encodes video data for HTML display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Random Seed and Device\n",
    "\n",
    "This cell ensures reproducibility by setting random seeds and configures the device (GPU or CPU) for computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Explanation:\n",
    "# - torch.manual_seed(42): Sets PyTorch's random seed for reproducible results.\n",
    "# - np.random.seed(42): Sets NumPy's random seed for consistency.\n",
    "# - device: Selects GPU (cuda) if available, else CPU, for tensor operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Reservoir Parameters\n",
    "\n",
    "This cell defines the physical parameters of the 3D reservoir and the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reservoir parameters\n",
    "phi = 0.2  # Porosity\n",
    "k = 0.1  # Permeability (Darcy)\n",
    "mu = 1.0  # Viscosity (cP)\n",
    "ct = 1e-6  # Total compressibility (1/Pa)\n",
    "q0 = 0.01  # Injection rate (m^3/s)\n",
    "well_pos = (0.5, 0.5, 0.5)  # Well location in 3D\n",
    "p_base = 1000.0  # Base pressure (Pa)\n",
    "p_scale = 1000.0  # Scale for normalization\n",
    "\n",
    "# Explanation:\n",
    "# - phi: Porosity, fraction of pore volume (0.2).\n",
    "# - k: Permeability, ease of fluid flow (0.1 Darcy).\n",
    "# - mu: Fluid viscosity (1.0 cP).\n",
    "# - ct: Total compressibility (1e-6 1/Pa), accounts for fluid and rock.\n",
    "# - q0: Injection rate at the well (0.01 m^3/s).\n",
    "# - well_pos: Coordinates of the injection well (0.5, 0.5, 0.5) in 3D.\n",
    "# - p_base: Initial/base pressure (1000 Pa).\n",
    "# - p_scale: Scaling factor for pressure normalization (1000 Pa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define PINN Model\n",
    "\n",
    "This cell defines the PINN neural network architecture with 8 layers, accepting 4 inputs (x, y, z, t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture (8 layers, 200 neurons)\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 200),  # 4 inputs: x, y, z, t\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x) * p_scale + p_base  # Scale and shift output\n",
    "\n",
    "# Explanation:\n",
    "# - PINN: Inherits from nn.Module, defining a neural network.\n",
    "# - __init__: Constructs an 8-layer network:\n",
    "#   - Input layer: 4 inputs (x, y, z, t) for 3D spatial and temporal coordinates.\n",
    "#   - 6 hidden layers: 200 neurons each, with Tanh activation.\n",
    "#   - Output layer: 1 output (pressure p).\n",
    "# - forward: Computes the network output, scaling by p_scale (1000) and shifting by p_base (1000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute PDE Residual\n",
    "\n",
    "This cell defines a function to compute the residual of the 3D PDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute PDE residual\n",
    "def compute_pde_residual(model, x, y, z, t):\n",
    "    inputs = torch.stack([x, y, z, t], dim=1).requires_grad_(True).to(device)\n",
    "    p = model(inputs)\n",
    "    \n",
    "    # Compute gradients\n",
    "    p_grad = torch.autograd.grad(p, inputs, grad_outputs=torch.ones_like(p), create_graph=True)[0]\n",
    "    p_x, p_y, p_z, p_t = p_grad[:, 0], p_grad[:, 1], p_grad[:, 2], p_grad[:, 3]\n",
    "    \n",
    "    # Second derivatives\n",
    "    p_xx = torch.autograd.grad(p_x, inputs, grad_outputs=torch.ones_like(p_x), create_graph=True)[0][:, 0]\n",
    "    p_yy = torch.autograd.grad(p_y, inputs, grad_outputs=torch.ones_like(p_y), create_graph=True)[0][:, 1]\n",
    "    p_zz = torch.autograd.grad(p_z, inputs, grad_outputs=torch.ones_like(p_z), create_graph=True)[0][:, 2]\n",
    "    \n",
    "    # Source term\n",
    "    sigma = 0.05\n",
    "    q = q0 * torch.exp(-((x - well_pos[0])**2 + (y - well_pos[1])**2 + (z - well_pos[2])**2) / (2 * sigma**2))\n",
    "    \n",
    "    # PDE: phi * ct * dp/dt - (k/mu) * (d^2p/dx^2 + d^2p/dy^2 + d^2p/dz^2) = q\n",
    "    residual = phi * ct * p_t - (k / mu) * (p_xx + p_yy + p_zz) - q\n",
    "    return residual\n",
    "\n",
    "# Explanation:\n",
    "# - compute_pde_residual: Computes the residual of the 3D PDE.\n",
    "# - inputs: Combines x, y, z, t into a tensor, with requires_grad=True for differentiation.\n",
    "# - p: Predicted pressure from the PINN model.\n",
    "# - p_grad: Computes first derivatives (p_x, p_y, p_z, p_t) using autograd.\n",
    "# - p_xx, p_yy, p_zz: Computes second derivatives for the 3D Laplacian.\n",
    "# - q: 3D Gaussian source term centered at well_pos.\n",
    "# - residual: PDE residual, minimized to enforce the physical law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Sparse Dataset\n",
    "\n",
    "This cell loads the 3D pressure data from `data/reservoir_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sparse dataset from CSV\n",
    "try:\n",
    "    data_df = pd.read_csv(\"data/reservoir_data.csv\")\n",
    "    if not all(col in data_df.columns for col in ['x', 'y', 'z', 't', 'p']):\n",
    "        raise ValueError(\"CSV file must contain columns: x, y, z, t, p\")\n",
    "    data = torch.tensor(data_df[['x', 'y', 'z', 't', 'p']].values, dtype=torch.float32).to(device)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/reservoir_data.csv' not found. Please provide the CSV file.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading CSV file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "x_d, y_d, z_d, t_d, p_d = data[:, 0], data[:, 1], data[:, 2], data[:, 3], data[:, 4]\n",
    "N_d = len(data)\n",
    "\n",
    "# Explanation:\n",
    "# - data_df: Reads 'data/reservoir_data.csv' with 50 points (5 original, 45 augmented).\n",
    "# - Validation: Ensures columns x, y, z, t, p exist.\n",
    "# - data: Converts DataFrame to a PyTorch tensor, moved to device.\n",
    "# - x_d, y_d, z_d, t_d, p_d: Extracts 3D coordinates, time, and pressure.\n",
    "# - N_d: Number of data points (50).\n",
    "# - Error handling: Exits on file not found or invalid format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Collocation Points\n",
    "\n",
    "This cell generates 3D points for PDE, boundary, and initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate collocation points with adaptive sampling\n",
    "N_r = 20000  # Collocation points\n",
    "N_b = 2000   # Boundary points\n",
    "N_i = 2000   # Initial condition points\n",
    "N_r_adaptive = 10000  # Adaptive points\n",
    "\n",
    "# Random collocation points\n",
    "x_r = torch.rand(N_r).to(device)\n",
    "y_r = torch.rand(N_r).to(device)\n",
    "z_r = torch.rand(N_r).to(device)\n",
    "t_r = torch.rand(N_r).to(device)\n",
    "\n",
    "# Adaptive sampling near well position\n",
    "x_r_adaptive = torch.normal(mean=0.5, std=0.1, size=(N_r_adaptive,)).clamp(0, 1).to(device)\n",
    "y_r_adaptive = torch.normal(mean=0.5, std=0.1, size=(N_r_adaptive,)).clamp(0, 1).to(device)\n",
    "z_r_adaptive = torch.normal(mean=0.5, std=0.1, size=(N_r_adaptive,)).clamp(0, 1).to(device)\n",
    "t_r_adaptive = torch.rand(N_r_adaptive).to(device)\n",
    "\n",
    "x_r = torch.cat([x_r, x_r_adaptive])\n",
    "y_r = torch.cat([y_r, y_r_adaptive])\n",
    "z_r = torch.cat([z_r, z_r_adaptive])\n",
    "t_r = torch.cat([t_r, t_r_adaptive])\n",
    "\n",
    "# Boundary points (faces of the cube)\n",
    "x_b = torch.cat([torch.zeros(N_b//6), torch.ones(N_b//6), torch.rand(N_b//3), torch.rand(N_b//3)]).to(device)\n",
    "y_b = torch.cat([torch.rand(N_b//3), torch.rand(N_b//3), torch.zeros(N_b//6), torch.ones(N_b//6)]).to(device)\n",
    "z_b = torch.cat([torch.rand(N_b//3), torch.rand(N_b//3), torch.rand(N_b//3), torch.rand(N_b//3)]).to(device)\n",
    "t_b = torch.rand(N_b).to(device)\n",
    "\n",
    "# Initial condition points\n",
    "x_i = torch.rand(N_i).to(device)\n",
    "y_i = torch.rand(N_i).to(device)\n",
    "z_i = torch.rand(N_i).to(device)\n",
    "t_i = torch.zeros(N_i).to(device)\n",
    "\n",
    "# Explanation:\n",
    "# - N_r, N_b, N_i, N_r_adaptive: Number of points for PDE, boundaries, initial conditions, and adaptive sampling.\n",
    "# - Collocation points: Randomly sampled in [0,1]^3 for x, y, z, and t for PDE enforcement.\n",
    "# - Adaptive points: Sampled near well (0.5, 0.5, 0.5) to focus on injection region.\n",
    "# - Boundary points: Sampled on cube faces (x=0,1; y=0,1; z=0,1) with random t.\n",
    "# - Initial condition points: Random x, y, z with t=0.\n",
    "# - All tensors are moved to device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Initialize Model and Optimizer\n",
    "\n",
    "This cell initializes the PINN model and sets up the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "model = PINN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=2000, gamma=0.5)\n",
    "\n",
    "# Explanation:\n",
    "# - model: Instantiates the 3D PINN model and moves it to device.\n",
    "# - optimizer: Uses Adam optimizer with learning rate 0.001.\n",
    "# - scheduler: Reduces learning rate by half every 2000 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Loop (Adam)\n",
    "\n",
    "This cell trains the PINN using Adam, minimizing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (Adam)\n",
    "epochs = 20000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # PDE residual loss\n",
    "    residual = compute_pde_residual(model, x_r, y_r, z_r, t_r)\n",
    "    loss_pde = torch.mean(residual**2)\n",
    "    \n",
    "    # Boundary condition loss\n",
    "    inputs_b = torch.stack([x_b, y_b, z_b, t_b], dim=1).requires_grad_(True).to(device)\n",
    "    p_b = model(inputs_b)\n",
    "    p_grad_b = torch.autograd.grad(p_b, inputs_b, grad_outputs=torch.ones_like(p_b), create_graph=True)[0]\n",
    "    p_x_b, p_y_b, p_z_b = p_grad_b[:, 0], p_grad_b[:, 1], p_grad_b[:, 2]\n",
    "    \n",
    "    mask_x0 = (x_b == 0)\n",
    "    mask_x1 = (x_b == 1)\n",
    "    loss_bc_x = torch.mean(p_x_b[mask_x0]**2) + torch.mean(p_x_b[mask_x1]**2)\n",
    "    \n",
    "    mask_y0 = (y_b == 0)\n",
    "    mask_y1 = (y_b == 1)\n",
    "    loss_bc_y = torch.mean(p_y_b[mask_y0]**2) + torch.mean(p_y_b[mask_y1]**2)\n",
    "    \n",
    "    mask_z0 = (z_b == 0)\n",
    "    mask_z1 = (z_b == 1)\n",
    "    loss_bc_z = torch.mean(p_z_b[mask_z0]**2) + torch.mean(p_z_b[mask_z1]**2)\n",
    "    \n",
    "    loss_bc = loss_bc_x + loss_bc_y + loss_bc_z\n",
    "    \n",
    "    # Initial condition loss\n",
    "    inputs_i = torch.stack([x_i, y_i, z_i, t_i], dim=1).to(device)\n",
    "    p_i = model(inputs_i)\n",
    "    loss_ic = torch.mean(((p_i - p_base) / p_scale)**2)\n",
    "    \n",
    "    # Data loss\n",
    "    inputs_d = torch.stack([x_d, y_d, z_d, t_d], dim=1).to(device)\n",
    "    p_d_pred = model(inputs_d)\n",
    "    loss_data = torch.mean(((p_d_pred - p_d) / p_scale)**2)\n",
    "    \n",
    "    # Total loss\n",
    "    loss = loss_pde + 100 * loss_bc + 10000 * loss_ic + 1000000 * loss_data\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Residual-based adaptive sampling\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        residual_abs = torch.abs(residual)\n",
    "        top_indices = torch.topk(residual_abs, k=1000).indices\n",
    "        x_r = torch.cat([x_r, x_r[top_indices]])\n",
    "        y_r = torch.cat([y_r, y_r[top_indices]])\n",
    "        z_r = torch.cat([z_r, z_r[top_indices]])\n",
    "        t_r = torch.cat([t_r, t_r[top_indices]])\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        with torch.no_grad():\n",
    "            p_d_pred = model(inputs_d)\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}, \"\n",
    "                  f\"PDE: {loss_pde.item():.6f}, BC: {loss_bc.item():.6f}, \"\n",
    "                  f\"IC: {loss_ic.item():.6f}, Data: {loss_data.item():.6f}\")\n",
    "            print(\"Predicted vs Actual pressures:\")\n",
    "            for i in range(N_d):\n",
    "                print(f\"Point {i+1}: Predicted={p_d_pred[i].item():.2f}, Actual={p_d[i].item():.2f}\")\n",
    "\n",
    "# Explanation:\n",
    "# - epochs: Trains for 20,000 iterations.\n",
    "# - loss_pde: Mean squared PDE residual in 3D.\n",
    "# - loss_bc: Enforces no-flow conditions on all cube faces.\n",
    "# - loss_ic: Enforces initial pressure p_base.\n",
    "# - loss_data: Matches predictions to the 50-point dataset.\n",
    "# - loss: Weighted sum of losses to balance contributions.\n",
    "# - Adaptive sampling: Adds points with high residual every 1000 epochs.\n",
    "# - Logging: Prints loss components and predictions every 1000 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. L-BFGS Optimization\n",
    "\n",
    "This cell refines the model using L-BFGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L-BFGS optimization\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1)\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    residual = compute_pde_residual(model, x_r, y_r, z_r, t_r)\n",
    "    loss_pde = torch.mean(residual**2)\n",
    "    inputs_b = torch.stack([x_b, y_b, z_b, t_b], dim=1).requires_grad_(True).to(device)\n",
    "    p_b = model(inputs_b)\n",
    "    p_grad_b = torch.autograd.grad(p_b, inputs_b, grad_outputs=torch.ones_like(p_b), create_graph=True)[0]\n",
    "    p_x_b, p_y_b, p_z_b = p_grad_b[:, 0], p_grad_b[:, 1], p_grad_b[:, 2]\n",
    "    loss_bc_x = torch.mean(p_x_b[(x_b == 0)]**2) + torch.mean(p_x_b[(x_b == 1)]**2)\n",
    "    loss_bc_y = torch.mean(p_y_b[(y_b == 0)]**2) + torch.mean(p_y_b[(y_b == 1)]**2)\n",
    "    loss_bc_z = torch.mean(p_z_b[(z_b == 0)]**2) + torch.mean(p_z_b[(z_b == 1)]**2)\n",
    "    loss_bc = loss_bc_x + loss_bc_y + loss_bc_z\n",
    "    inputs_i = torch.stack([x_i, y_i, z_i, t_i], dim=1).to(device)\n",
    "    p_i = model(inputs_i)\n",
    "    loss_ic = torch.mean(((p_i - p_base) / p_scale)**2)\n",
    "    inputs_d = torch.stack([x_d, y_d, z_d, t_d], dim=1).to(device)\n",
    "    p_d_pred = model(inputs_d)\n",
    "    loss_data = torch.mean(((p_d_pred - p_d) / p_scale)**2)\n",
    "    loss = loss_pde + 100 * loss_bc + 10000 * loss_ic + 1000000 * loss_data\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.step(closure)\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"L-BFGS Iteration {i+1}, Loss: {closure().item():.6f}\")\n",
    "\n",
    "# Explanation:\n",
    "# - optimizer: Uses L-BFGS with learning rate 0.1.\n",
    "# - closure: Computes the same loss as Adam, adapted for 3D.\n",
    "# - Training: Runs 100 iterations.\n",
    "# - Logging: Prints loss every 10 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save the Model\n",
    "\n",
    "This cell saves the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'reservoir_pinn.pth')\n",
    "print(\"Model saved as 'reservoir_pinn.pth'\")\n",
    "\n",
    "# Explanation:\n",
    "# - torch.save: Saves the model's parameters to 'reservoir_pinn.pth'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Validate Model\n",
    "\n",
    "This cell computes the MSE and compares predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation: Compute MSE and print predictions\n",
    "with torch.no_grad():\n",
    "    p_d_pred = model(inputs_d)\n",
    "    mse_data = torch.mean(((p_d_pred - p_d) / p_scale)**2).item()\n",
    "    print(f\"Final MSE on sparse data (normalized): {mse_data:.6f}\")\n",
    "    print(\"Predicted vs Actual pressures:\")\n",
    "    for i in range(N_d):\n",
    "        print(f\"Point {i+1}: Predicted={p_d_pred[i].item():.2f}, Actual={p_d[i].item():.2f}\")\n",
    "\n",
    "# Explanation:\n",
    "# - torch.no_grad(): Disables gradient tracking.\n",
    "# - p_d_pred: Predicts pressure at 50 data points.\n",
    "# - mse_data: Computes normalized MSE.\n",
    "# - Prints MSE and predicted vs. actual pressures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test Loading the Model\n",
    "\n",
    "This cell tests reloading the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the saved model\n",
    "def load_and_predict(model_class, model_path, inputs, device):\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(inputs)\n",
    "    return predictions\n",
    "\n",
    "loaded_predictions = load_and_predict(PINN, 'reservoir_pinn.pth', inputs_d, device)\n",
    "print(\"Predictions from loaded model:\")\n",
    "for i in range(N_d):\n",
    "    print(f\"Point {i+1}: Loaded={loaded_predictions[i].item():.2f}, Actual={p_d[i].item():.2f}\")\n",
    "\n",
    "# Explanation:\n",
    "# - load_and_predict: Loads and predicts with the saved model.\n",
    "# - Verifies consistency of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Visualize Pressure Field (Static)\n",
    "\n",
    "This cell plots a 2D pressure slice at a fixed z-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of pressure field (2D slice at z=0.5)\n",
    "def plot_pressure_slice(model, t_val, z_val, data_df):\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y = np.linspace(0, 1, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = np.full_like(X, z_val)\n",
    "    T = np.full_like(X, t_val)\n",
    "    \n",
    "    inputs = torch.tensor(np.stack([X.flatten(), Y.flatten(), Z.flatten(), T.flatten()], axis=1), \n",
    "                         dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        P = model(inputs).cpu().numpy().reshape(X.shape)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(X, Y, P, levels=20, cmap=\"viridis\")\n",
    "    plt.colorbar(label=\"Pressure (Pa)\")\n",
    "    mask = np.abs(data_df['z'] - z_val) < 0.1  # Points near z_val\n",
    "    plt.scatter(data_df['x'][mask], data_df['y'][mask], c=\"red\", label=\"Data points\")\n",
    "    plt.title(f\"Pressure at z={z_val:.2f}, t={t_val:.2f}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"pressure_z_{z_val:.2f}_t_{t_val:.2f}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot slices at different times\n",
    "plot_pressure_slice(model, 0.0, 0.5, data_df)\n",
    "plot_pressure_slice(model, 0.5, 0.5, data_df)\n",
    "plot_pressure_slice(model, 1.0, 0.5, data_df)\n",
    "\n",
    "# Explanation:\n",
    "# - plot_pressure_slice: Plots a 2D pressure slice at fixed z and t.\n",
    "# - X, Y, Z, T: Meshgrid for x, y with constant z and t.\n",
    "# - inputs: 4D tensor for model prediction.\n",
    "# - P: Predicted pressures reshaped to 2D grid.\n",
    "# - Plot: Contour plot with data points near z_val, saved as PNG.\n",
    "# - Calls: Plots at t=0.0, 0.5, 1.0 for z=0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Visualize Pressure Field (Animation)\n",
    "\n",
    "This cell generates an animation of a 2D pressure slice over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation of pressure field (slice at z=0.5)\n",
    "def animate_pressure_slice(model, data_df, z_val, device, filename='pressure_animation.mp4'):\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y = np.linspace(0, 1, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = np.full_like(X, z_val)\n",
    "    times = np.linspace(0, 1, 50)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    inputs = torch.tensor(np.stack([X.flatten(), Y.flatten(), Z.flatten(), np.zeros_like(X.flatten())], axis=1), \n",
    "                         dtype=torch.float32).to(device)\n",
    "\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        t_val = times[frame]\n",
    "        inputs[:, 3] = t_val\n",
    "        with torch.no_grad():\n",
    "            P = model(inputs).cpu().numpy().reshape(X.shape)\n",
    "        contour = ax.contourf(X, Y, P, levels=20, cmap=\"viridis\")\n",
    "        mask = np.abs(data_df['z'] - z_val) < 0.1\n",
    "        ax.scatter(data_df['x'][mask], data_df['y'][mask], c=\"red\", label=\"Data points\")\n",
    "        ax.set_title(f\"Pressure at z={z_val:.2f}, t={t_val:.2f}\")\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"y\")\n",
    "        ax.legend()\n",
    "        if frame == 0:\n",
    "            fig.colorbar(contour, ax=ax, label=\"Pressure (Pa)\")\n",
    "        return contour,\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=len(times), interval=100, blit=False)\n",
    "    anim.save(filename, writer='ffmpeg', fps=10)\n",
    "    plt.close(fig)\n",
    "    return filename\n",
    "\n",
    "# Generate and display animation\n",
    "animation_file = animate_pressure_slice(model, data_df, 0.5, device)\n",
    "with open(animation_file, 'rb') as f:\n",
    "    video_data = f.read()\n",
    "HTML(f\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"data:video/mp4;base64,{base64.b64encode(video_data).decode()}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")\n",
    "\n",
    "# Explanation:\n",
    "# - animate_pressure_slice: Animates a 2D pressure slice at fixed z over t=[0,1].\n",
    "# - X, Y, Z: Meshgrid for x, y with constant z.\n",
    "# - times: 50 frames for animation.\n",
    "# - inputs: 4D tensor, updated with t_val per frame.\n",
    "# - update: Updates contour plot with data points near z_val.\n",
    "# - FuncAnimation: Saves animation as 'pressure_animation.mp4' at 10 fps.\n",
    "# - HTML: Displays animation inline using base64 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook explains the 3D Reservoir PINN implementation, covering:\n",
    "- Setting up the 3D environment and parameters.\n",
    "- Defining the PINN model and 3D PDE residual.\n",
    "- Loading 3D data from `data/reservoir_data.csv` (50 points).\n",
    "- Generating 3D points for PDE, boundary, and initial conditions.\n",
    "- Training with Adam and L-BFGS.\n",
    "- Validating and visualizing results (2D slices and animation).\n",
    "# - Plotting the network architecture.\n",
    "\n",
    "Run this notebook with `data/reservoir_data.csv` and FFmpeg installed to explore the 3D pressure dynamics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}